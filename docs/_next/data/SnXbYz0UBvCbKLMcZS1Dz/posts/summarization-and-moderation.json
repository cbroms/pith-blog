{"pageProps":{"postData":{"id":"summarization-and-moderation","contentHtml":"<p>The bulk of phase II is summarization. Phase 1 focused on how people interact through the familiar interface of chat. Through phase II, we will be building a space for them to develop an ongoing-summary of their conversation.</p>\n<p>We have implemented a feature for people to note the \"theme\" of a discussion. The theme is essentially the goal, such as to decide on a plan of action, to brainstorm, to share experiences, to decide which solutions have more support. The form of this summary will likely change depending on this theme. For example, through a conversation on what the best plan of action is on building a gala, the participants of the discussion may want to keep a current bullet-list of to-do's. Or, through a conversation on brainstorming, it is a series of blocks that have been noted as particularly interesting. In sharing stories, it could be a summary of common strands throughout stories or particularly noteworthy instances. In deciding on solutions, it could be a map of ideas, where each general solution has its own space on the summary interface.</p>\n<p>The summary interface itself will take up roughly half of the discussion screen, where the chat takes up the other half. People will have the ability to add blocks to this space and possibly create new blobs of text and modify them. Because one of the main purposes of this space is for every participant to easily see all the relevant content of a discussion, the space is constrained—there is a limit to how much information can be added. We have considered a number of possible forms this summarization could take so that people could have some structure to organize their discussion.</p>\n<h3>Summarization Design Options</h3>\n<ul>\n<li>Free-flow. There is no additional constraint to the space except for the limit on the amount of information within.</li>\n<li>Top-N blocks. These blocks are directly transcluded from the conversation by anyone.</li>\n<li>Top-N blocks, editable by anyone.</li>\n<li>Most quoted/replied to blocks are automatically added to the summary. These blocks could summarize points of most contention.</li>\n<li>Graphical-based summary. Blocks or blobs of text are nodes. Connectors like arrows can be used between. Such as, this node addresses that node. Or, these two nodes can be used in combination. Shapes, like circles and squares, can be used to organize nodes into sets.</li>\n<li>Staging area + summary. The summary space is divided so there is a staging area. The other templates allow anyone to modify the elements in the summary. New elements are put into the staging area and only moved to the summary area once all or most people agree they should be included.</li>\n</ul>\n<p>Once a conversation has expired or been marked as ended, the summary will replace the discussion on the main board of discussions. This way, other people have a good idea of the salient points of the discussion. Because the summarization is the only thing that is left of a discussion after it is finished—the posts/blocks themselves are essentially gone and the names of the participants are not saved—the participants may want to consider what is worth sharing with the outside.</p>\n<p>For the most part, we hypothesize that people will be able to discuss or trust each other on modifying the summary. If people do not agree with a modification, they could continue to discuss the point and in the process may clear up a previous misunderstanding.</p>\n<p>However, it is imaginable this will not always be the case. Some people may intentionally detrack the conversation or mess up the summary board. Or, some people may use abusive language and <em>ad hominem</em> attacks when talking to others. Therefore, we considered the following ways \"trolling\" or abuse could be moderated.</p>\n<h3>Moderation Systems</h3>\n<ul>\n<li>Global moderation. Individuals flag certain posts as abuse or file a complaint against a person in their discussion and list a reason. A set of moderators for the entire platform will review the flags and complaints and decide which ones are legitimate and further action against the person in question should be taken.</li>\n<li>The greatest issue with this approach is the lack of context. Is the post abusive given the course of the conversation? Sometimes it may be hard to tell. Would the other members agree that the post is abusive?</li>\n<li>Furthermore, global moderation requires a significant amount of trust in a few volunteers or chosen people to do the job well.</li>\n<li>This approach may be better suited for an organization with their own Pith board. Having global moderation could impose organization-wide standards.</li>\n<li>The offender can be banned from a discussion after some kind of vote/decision. If a person is banned many times, they may go through a review for suspension on the platform itself.</li>\n<li>The advantage of this approach is that the participants have the most context is deciding whether the actions of a person in a discussion are abuse.</li>\n<li>However, this approach requires more careful consideration for when people can consider banning someone. Here are some possibilities.</li>\n<li>Raise a vote once 3 (or N) number of that person's posts have been marked as abusive.</li>\n<li>People can mark a person as abusive based on their actions and take away the mark should the person improve their behavior. Once a certain number of marks has been reached at once, maybe due to a particularly severe incident of abusive behavior or repeated abusive behavior, the vote for expulsion may be opened.</li>\n<li>The creator may fix how to moderate the discussion based on some of these predefined options. Such as, open the ban after N blocks are flagged as abuse or after M people continue to mark a person as abusive.</li>\n<li>This approach may be better suited to the world-wide version of Pith, where anyone can make a discussion on the board. People's judgment for reasonable behavior is trusted over a select few individuals.</li>\n</ul>\n<p>Some types of malicious action are more insidious, such as misinformation. Though the giver of the information is aware it is inaccurate, the receivers may not. We considered some ways to combat this.</p>\n<h3>Features to Address Misinformation</h3>\n<ul>\n<li>People can use a \"questionable\" flag to mark a block/post. The \"questionable\" flag will outline or otherwise highlight the block/post. The flagger can write a reason beneath that block/post indicating why they are skeptical about its validity.</li>\n<li>Allowing people to search content on Wikipedia or other generally well-regarded crowd-source knowledge bases to fact-check a block. The ability to search would be as simple as a click of a button by the a questionable block or using a special search when creating a new post. Realistically, in an ongoing conversation, people may not always think to fact-check every questionable statement in a fact checker or information site on another browser tab. This feature greatly minimizes the overhead to fact-check.</li>\n</ul>\n","title":"Summarization and Moderation","date":"2020-07-20","author":"Sydney Zheng","summary":"The bulk of phase II is summarization. Phase 1 focused on how people interact through the familiar interface of chat. Through phase II, we will be building a space for them to develop an ongoing-summary of their conversation."}},"__N_SSG":true}